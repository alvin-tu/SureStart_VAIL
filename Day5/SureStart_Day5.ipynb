{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\n/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import json\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path1 = '/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json'\ndf = pd.read_json(file_path1,lines=True)\ndf = df[['headline','is_sarcastic']]\ndf.head()\n","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                            headline  is_sarcastic\n0  former versace store clerk sues over secret 'b...             0\n1  the 'roseanne' revival catches up to our thorn...             0\n2  mom starting to fear son's web series closest ...             1\n3  boehner just wants wife to listen, not come up...             1\n4  j.k. rowling wishes snape happy birthday in th...             0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline</th>\n      <th>is_sarcastic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>former versace store clerk sues over secret 'b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the 'roseanne' revival catches up to our thorn...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mom starting to fear son's web series closest ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>boehner just wants wife to listen, not come up...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>j.k. rowling wishes snape happy birthday in th...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"headlines = df['headline'].values.tolist()\nsarcastic = df['is_sarcastic'].values.tolist()\n\nprint('Length of data {}'.format(len(headlines)))","execution_count":4,"outputs":[{"output_type":"stream","text":"Length of data 26709\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_size = 20000\ntest_size = 6709\n\ntrain_x = headlines[:training_size]\ntest_x = headlines[training_size:]\ntrain_y = np.array(sarcastic[:training_size])\ntest_y = np.array(sarcastic[training_size:])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_x[0])\nprint(train_y[0])","execution_count":6,"outputs":[{"output_type":"stream","text":"former versace store clerk sues over secret 'black code' for minority shoppers\n0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vocab_size = 2000   #number of words in tokenizer\nembedding_dim = 100\nmax_len = 16\n\ntokenizer = Tokenizer(oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(train_x)\n\nword_index = tokenizer.word_index\nvocab_size = len(word_index)\nsequence_train = tokenizer.texts_to_sequences(train_x)\nseq_padd_train = pad_sequences(sequence_train,padding='post',truncating='post',maxlen=max_len)\n\n#test\nsequence_test = tokenizer.texts_to_sequences(test_x)\nseq_padd_test = pad_sequences(sequence_test,padding='post',truncating='post',maxlen=max_len)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sequence_train[0])\nprint(seq_padd_train[0])\nprint(seq_padd_train.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"[328, 12776, 799, 3405, 2404, 47, 389, 2214, 12777, 6, 2614, 8863]\n[  328 12776   799  3405  2404    47   389  2214 12777     6  2614  8863\n     0     0     0     0]\n(20000, 16)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget --no-check-certificate \\\n    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n    -O /tmp/glove.6B.100d.txt","execution_count":9,"outputs":[{"output_type":"stream","text":"wget: /opt/conda/lib/libuuid.so.1: no version information available (required by wget)\n--2021-02-15 23:09:07--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\nResolving storage.googleapis.com (storage.googleapis.com)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address ‘storage.googleapis.com’\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings_index = {};\nwith open('/tmp/glove.6B.100d.txt') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:],dtype='float32')\n        embeddings_index[word] = coefs\n    ","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating embedding matrix\nembeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embeddings_matrix[i] = embedding_vector","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_len,weights=[embeddings_matrix], trainable=False),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True)),\n    #return_sequences: will ensure output of first LSTM layer matches next\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(6, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","execution_count":12,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 16, 100)           2563800   \n_________________________________________________________________\nbidirectional (Bidirectional (None, 16, 128)           84480     \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 64)                41216     \n_________________________________________________________________\nflatten (Flatten)            (None, 64)                0         \n_________________________________________________________________\ndense (Dense)                (None, 6)                 390       \n_________________________________________________________________\ndropout (Dropout)            (None, 6)                 0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 7         \n=================================================================\nTotal params: 2,689,893\nTrainable params: 126,093\nNon-trainable params: 2,563,800\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 20\nhistory = model.fit(seq_padd_train, train_y , epochs=num_epochs, validation_data=(seq_padd_test,test_y))","execution_count":null,"outputs":[{"output_type":"stream","text":"Train on 20000 samples, validate on 6709 samples\nEpoch 1/20\n19968/20000 [============================>.] - ETA: 0s - loss: 0.6882 - accuracy: 0.5602 ETA: 0s - loss: 0.688","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(num_epochs)\n\nplt.subplot(2,1,1)\nplt.plot(epochs,train_accuracy)\nplt.plot(epochs,val_accuracy)\nplt.legend(['train_acc','val_acc'])\nplt.title('Accuracy')\nplt.show()\n\nplt.subplot(2,1,2)\nplt.plot(epochs,train_loss)\nplt.plot(epochs,val_loss)\nplt.legend(['train_loss','val_loss'])\nplt.title('Loss')\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}